{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Training and Tuning with Ray\n",
    "\n",
    "## Part 1: Training with Ray Train and Xgboost\n",
    "In this task, you will train a machine learning model using the preprocessed data. The goal is to train an Xgboost model to predict the user rating for a product. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 16:44:42,369\tINFO util.py:154 -- Outdated packages:\n",
      "  ipywidgets==7.8.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-03-13 16:44:42,377\tINFO worker.py:1540 -- Connecting to existing Ray cluster at address: 10.47.192.26:6380...\n",
      "2024-03-13 16:44:42,408\tINFO worker.py:1715 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32mhttp://10.47.192.26:8265 \u001b[39m\u001b[22m\n",
      "2024-03-13 16:44:43,214\tINFO util.py:154 -- Outdated packages:\n",
      "  ipywidgets==7.8.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "ray.init() # connect to existing Ray cluster\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "seed = 41\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "from ray.train.xgboost import XGBoostTrainer\n",
    "from ray.train import ScalingConfig, RunConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear out previously saved results\n",
    "!rm -f res_2_2.json res_2_1.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Metadata Fetch Progress 0:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parquet Files Sample 0:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the preprocessed dataset as dense vectors in the parquet format\n",
    "train_data_path=os.path.expanduser(\"~/public/pa3/ml_features_train.parquet\")\n",
    "train_data = ray.data.read_parquet(train_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Instantiate a Ray trainer and train an xgboost model on the training dataset. The model should be trained with a regression objective to minimize the mean squared error. The `max_depth` parameter of the model must be set to 3, the `eta` value to 0.3. All other parameters of the model should be left to default values.\n",
    "\n",
    "Note: Ray will by default try to store results in `~/ray_results`. This can throw permission errors in DataHub, so you can change the location to `~/private/ray_results`. [Docs](https://docs.ray.io/en/latest/train/api/doc/ray.train.RunConfig.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "34ea41251d93babc2129bb53cc900b91",
     "grade": true,
     "grade_id": "cell-75f2ec9ff54d45a6",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "trainer = XGBoostTrainer(label_column = \"overall\",\n",
    "                         params = {'objective': 'reg:squarederror',\n",
    "                                   'max_depth':3,\n",
    "                                    'eta':0.3},\n",
    "                         scaling_config=ScalingConfig(num_workers = 3, use_gpu = False, resources_per_worker = {\"CPU\" : 6}),\n",
    "                         datasets = {'train':train_data}\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-03-13 16:45:45</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:56.19        </td></tr>\n",
       "<tr><td>Memory:      </td><td>124.5/503.6 GiB    </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 18.0/24 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                </th><th>status    </th><th>loc             </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train-rmse</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>XGBoostTrainer_ad2b5_00000</td><td>TERMINATED</td><td>10.35.0.20:22653</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         51.8878</td><td style=\"text-align: right;\">    0.884518</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=22653, ip=10.35.0.20)\u001b[0m [RayXGBoost] Created 3 new actors (3 total actors). Waiting until actors are ready for training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=22653, ip=10.35.0.20) Read progress 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=22653, ip=10.35.0.20)\u001b[0m [RayXGBoost] Starting XGBoost training.\n",
      "\u001b[36m(_RemoteRayXGBoostActor pid=22809, ip=10.35.0.20)\u001b[0m [16:45:06] task [xgboost.ray]:140480536028736 got new rank 0\n",
      "\u001b[36m(XGBoostTrainer pid=22653, ip=10.35.0.20)\u001b[0m Training in progress (30 seconds since last restart).\n",
      "\u001b[36m(_RemoteRayXGBoostActor pid=43765)\u001b[0m [16:45:06] task [xgboost.ray]:140087680559712 got new rank 2\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(XGBoostTrainer pid=22653, ip=10.35.0.20)\u001b[0m [RayXGBoost] Finished XGBoost training on training data with total N=18,444,174 in 51.91 seconds (40.01 pure XGBoost training time).2024-03-13 16:45:45,666\tINFO tune.py:1042 -- Total run time: 58.04 seconds (56.17 seconds for the tuning loop).\n",
      "\n",
      "\u001b[36m(XGBoostTrainer pid=22653, ip=10.35.0.20)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/a1jadhav/ray_results/XGBoostTrainer_2024-03-13_16-44-47/XGBoostTrainer_ad2b5_00000_0_2024-03-13_16-44-49/checkpoint_000000)\n"
     ]
    }
   ],
   "source": [
    "result = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result(\n",
      "  metrics={'train-rmse': 0.8845177330600246},\n",
      "  path='/home/a1jadhav/ray_results/XGBoostTrainer_2024-03-13_16-44-47/XGBoostTrainer_ad2b5_00000_0_2024-03-13_16-44-49',\n",
      "  filesystem='local',\n",
      "  checkpoint=Checkpoint(filesystem=local, path=/home/a1jadhav/ray_results/XGBoostTrainer_2024-03-13_16-44-47/XGBoostTrainer_ad2b5_00000_0_2024-03-13_16-44-49/checkpoint_000000)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing test data performance\n",
    "\n",
    "Next, use the trained model to generate predictions on test data. Calculate the root mean square error (RMSE) of\n",
    "the test predictions and report it in the output. \n",
    "\n",
    "For this task, we will make use of [`map_batches`](https://docs.ray.io/en/latest/data/api/doc/ray.data.Dataset.map_batches.html) to make a stateful transformation of the test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parquet Files Sample 0:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_data_path=os.path.expanduser(\"~/public/pa3/ml_features_test.parquet\")\n",
    "test_dataset= ray.data.read_parquet(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = trainer.get_model(result.checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e963f3d7617d224566dc2f282efbc9de",
     "grade": true,
     "grade_id": "cell-fd7e85b107f63b98",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ray.train import Checkpoint\n",
    "import xgboost\n",
    "import math\n",
    "\n",
    "class Predictor:\n",
    "\n",
    "    def __init__(self, checkpoint: Checkpoint):\n",
    "        self.model = XGBoostTrainer.get_model(checkpoint)\n",
    "        self.label_col = \"overall\"\n",
    "\n",
    "    def __call__(self, batch: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Implement the following:\n",
    "        1. Get the predictions on a batch of data for an xgboost model as you would do normally.\n",
    "        2. Return the squared errors for each entry using the label column\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        X = batch.drop(columns=[self.label_col])\n",
    "        y_true = batch[self.label_col]\n",
    "        y_pred = self.model.predict(xgboost.DMatrix(X))\n",
    "        errors = (y_true - y_pred) ** 2\n",
    "        return {\"se\": errors}\n",
    "\n",
    "def predict_xgboost(test_dataset, result):\n",
    "    \"\"\"\n",
    "    Obtains the predictions for a test dataset given a `ray.train.Result` object and returns the squared errors for each entry\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    predictor = Predictor(result.checkpoint)\n",
    "    squared_errors = test_dataset.map_batches(predictor, batch_format = \"pandas\")\n",
    "    \n",
    "    return squared_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cd8eb3575a035a9f267274abe2885d2d",
     "grade": true,
     "grade_id": "cell-709a7156a1c24be1",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 16:45:47,384\tINFO set_read_parallelism.py:115 -- Using autodetected parallelism=200 for stage ReadParquet to satisfy DataContext.get_current().min_parallelism=200.\n",
      "2024-03-13 16:45:47,385\tINFO set_read_parallelism.py:122 -- To satisfy the requested parallelism of 200, each read task output is split into 9 smaller blocks.\n",
      "2024-03-13 16:45:47,386\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(Predictor)] -> LimitOperator[limit=1]\n",
      "2024-03-13 16:45:47,388\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-13 16:45:47,389\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 16:45:50,339\tINFO dataset.py:2488 -- Tip: Use `take_batch()` instead of `take() / show()` to return records in pandas or numpy batch format.\n",
      "2024-03-13 16:45:50,349\tINFO set_read_parallelism.py:115 -- Using autodetected parallelism=200 for stage ReadParquet to satisfy DataContext.get_current().min_parallelism=200.\n",
      "2024-03-13 16:45:50,350\tINFO set_read_parallelism.py:122 -- To satisfy the requested parallelism of 200, each read task output is split into 9 smaller blocks.\n",
      "2024-03-13 16:45:50,351\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(Predictor)] -> AllToAllOperator[Aggregate] -> LimitOperator[limit=1]\n",
      "2024-03-13 16:45:50,352\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-13 16:45:50,352\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- Aggregate 1:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Map 2:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Reduce 3:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 16:45:56,104\tINFO set_read_parallelism.py:115 -- Using autodetected parallelism=200 for stage ReadParquet to satisfy DataContext.get_current().min_parallelism=200.\n",
      "2024-03-13 16:45:56,104\tINFO set_read_parallelism.py:122 -- To satisfy the requested parallelism of 200, each read task output is split into 9 smaller blocks.\n",
      "2024-03-13 16:45:56,105\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(Predictor)]\n",
      "2024-03-13 16:45:56,106\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-13 16:45:56,106\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get the root mean squared error for the test dataset using the result.\n",
    "# Save the test rmse in `test_rmse` \n",
    "\n",
    "# YOUR CODE HERE\n",
    "squared_errors = predict_xgboost(test_dataset, result)\n",
    "test_rmse = math.sqrt(squared_errors.sum()/squared_errors.count())\n",
    "\n",
    "# write to file\n",
    "res = {\"test_rmse\": test_rmse, \n",
    "          \"train_rmse\": result.metrics[\"train-rmse\"]}\n",
    "with open(\"res_2_1.json\", \"w\") as f:\n",
    "    json.dump(res, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Tuning with Ray Tune\n",
    "\n",
    "We'll tune the following Xgboost hyperparameters:\n",
    "\n",
    "1. `max_depth`\n",
    "3. `subsample`\n",
    "4. `eta`\n",
    "\n",
    "You can read more about each hyperparameter in the [official docs](https://xgboost.readthedocs.io/en/stable/parameter.html). Since the overall search space is large, and our compute budget is limited, we'll focus on running 12 *trials* (or 12 instances of 3-tuples of hyperparameters) with a grid search.  Here are the values:\n",
    "\n",
    "1. `max_depth`: $[3, 4, 5]$ \n",
    "3. `subsample`: $[0.8, 1.0]$\n",
    "4. `eta`: $[0.3, 0.5]$\n",
    "\n",
    "\n",
    "Steps to implement, repeated from the problem statement:\n",
    "1. Create a new training and validation data from the original training data - with a random split of 75/25.\n",
    "2. Train Xgboost models with 12 hyperparameter trials over the given grid using Ray Tune. [Offical Example](https://docs.ray.io/en/latest/tune/examples/tune-xgboost.html)\n",
    "3. Select the best model with the lowest validation RMSE. \n",
    "4. Report the test RMSE for the best model and the lowest validation RMSE.\n",
    "\n",
    "Make sure to use the same `ScalingConfig` as before. Restrict the number of concurrent trials to 1 for memory efficiency. Store the final `tune.ResultGrid` object in `result_grid` and the best result in the variable `best_result`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4fe7c9d70b64a6c5c3ff1f37a127a51e",
     "grade": true,
     "grade_id": "cell-274485071ae6e581",
     "locked": false,
     "points": 25,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-03-13 16:56:51</td></tr>\n",
       "<tr><td>Running for: </td><td>00:10:31.15        </td></tr>\n",
       "<tr><td>Memory:      </td><td>130.9/503.6 GiB    </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 18.0/24 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                </th><th>status    </th><th>loc               </th><th style=\"text-align: right;\">  params/eta</th><th style=\"text-align: right;\">  params/max_depth</th><th style=\"text-align: right;\">  params/subsample</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train-rmse</th><th style=\"text-align: right;\">  val-rmse</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>XGBoostTrainer_e4665_00000</td><td>TERMINATED</td><td>10.47.192.26:47227</td><td style=\"text-align: right;\">         0.3</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">               0.8</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         51.0381</td><td style=\"text-align: right;\">    0.884277</td><td style=\"text-align: right;\">  0.88485 </td></tr>\n",
       "<tr><td>XGBoostTrainer_e4665_00001</td><td>TERMINATED</td><td>10.45.64.19:24886 </td><td style=\"text-align: right;\">         0.5</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">               0.8</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         46.3068</td><td style=\"text-align: right;\">    0.876538</td><td style=\"text-align: right;\">  0.877231</td></tr>\n",
       "<tr><td>XGBoostTrainer_e4665_00002</td><td>TERMINATED</td><td>10.47.192.26:49028</td><td style=\"text-align: right;\">         0.3</td><td style=\"text-align: right;\">                 4</td><td style=\"text-align: right;\">               0.8</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         46.3773</td><td style=\"text-align: right;\">    0.877908</td><td style=\"text-align: right;\">  0.878565</td></tr>\n",
       "<tr><td>XGBoostTrainer_e4665_00003</td><td>TERMINATED</td><td>10.45.64.19:25917 </td><td style=\"text-align: right;\">         0.5</td><td style=\"text-align: right;\">                 4</td><td style=\"text-align: right;\">               0.8</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         46.087 </td><td style=\"text-align: right;\">    0.871727</td><td style=\"text-align: right;\">  0.872406</td></tr>\n",
       "<tr><td>XGBoostTrainer_e4665_00004</td><td>TERMINATED</td><td>10.35.0.20:26109  </td><td style=\"text-align: right;\">         0.3</td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">               0.8</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         52.2955</td><td style=\"text-align: right;\">    0.873965</td><td style=\"text-align: right;\">  0.874649</td></tr>\n",
       "<tr><td>XGBoostTrainer_e4665_00005</td><td>TERMINATED</td><td>10.35.0.20:26723  </td><td style=\"text-align: right;\">         0.5</td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">               0.8</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         51.2324</td><td style=\"text-align: right;\">    0.867158</td><td style=\"text-align: right;\">  0.867836</td></tr>\n",
       "<tr><td>XGBoostTrainer_e4665_00006</td><td>TERMINATED</td><td>10.35.0.20:27343  </td><td style=\"text-align: right;\">         0.3</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">               1  </td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         47.8074</td><td style=\"text-align: right;\">    0.884268</td><td style=\"text-align: right;\">  0.884852</td></tr>\n",
       "<tr><td>XGBoostTrainer_e4665_00007</td><td>TERMINATED</td><td>10.47.192.26:51424</td><td style=\"text-align: right;\">         0.5</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">               1  </td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         41.6642</td><td style=\"text-align: right;\">    0.877016</td><td style=\"text-align: right;\">  0.877651</td></tr>\n",
       "<tr><td>XGBoostTrainer_e4665_00008</td><td>TERMINATED</td><td>10.35.0.20:28365  </td><td style=\"text-align: right;\">         0.3</td><td style=\"text-align: right;\">                 4</td><td style=\"text-align: right;\">               1  </td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         46.221 </td><td style=\"text-align: right;\">    0.87767 </td><td style=\"text-align: right;\">  0.87833 </td></tr>\n",
       "<tr><td>XGBoostTrainer_e4665_00009</td><td>TERMINATED</td><td>10.45.64.19:28404 </td><td style=\"text-align: right;\">         0.5</td><td style=\"text-align: right;\">                 4</td><td style=\"text-align: right;\">               1  </td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         48.3248</td><td style=\"text-align: right;\">    0.87133 </td><td style=\"text-align: right;\">  0.872067</td></tr>\n",
       "<tr><td>XGBoostTrainer_e4665_00010</td><td>TERMINATED</td><td>10.35.0.20:29231  </td><td style=\"text-align: right;\">         0.3</td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">               1  </td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         50.0127</td><td style=\"text-align: right;\">    0.873865</td><td style=\"text-align: right;\">  0.874575</td></tr>\n",
       "<tr><td>XGBoostTrainer_e4665_00011</td><td>TERMINATED</td><td>10.35.0.20:30003  </td><td style=\"text-align: right;\">         0.5</td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">               1  </td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         51.7369</td><td style=\"text-align: right;\">    0.867318</td><td style=\"text-align: right;\">  0.867972</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=47227)\u001b[0m [RayXGBoost] Created 3 new actors (3 total actors). Waiting until actors are ready for training.\n",
      "\u001b[36m(XGBoostTrainer pid=47227)\u001b[0m [RayXGBoost] Starting XGBoost training.\n",
      "\u001b[36m(_RemoteRayXGBoostActor pid=24644, ip=10.35.0.20)\u001b[0m [16:46:37] task [xgboost.ray]:140012045121136 got new rank 0\n",
      "\u001b[36m(XGBoostTrainer pid=47227)\u001b[0m Training in progress (31 seconds since last restart).\n",
      "\u001b[36m(_RemoteRayXGBoostActor pid=47508)\u001b[0m [16:46:37] task [xgboost.ray]:139622141098544 got new rank 2\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(XGBoostTrainer pid=47227)\u001b[0m [RayXGBoost] Finished XGBoost training on training data with total N=13,833,129 in 51.06 seconds (38.86 pure XGBoost training time).\n",
      "\u001b[36m(XGBoostTrainer pid=47227)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/a1jadhav/ray_results/XGBoostTrainer_2024-03-13_16-46-20/XGBoostTrainer_e4665_00000_0_eta=0.3000,max_depth=3,subsample=0.8000_2024-03-13_16-46-20/checkpoint_000000)\n",
      "\u001b[36m(XGBoostTrainer pid=24886, ip=10.45.64.19)\u001b[0m [RayXGBoost] Created 3 new actors (3 total actors). Waiting until actors are ready for training.\n",
      "\u001b[36m(XGBoostTrainer pid=24886, ip=10.45.64.19)\u001b[0m [RayXGBoost] Starting XGBoost training.\n",
      "\u001b[36m(_RemoteRayXGBoostActor pid=25047, ip=10.35.0.20)\u001b[0m [16:47:28] task [xgboost.ray]:139827630228816 got new rank 0\n",
      "\u001b[36m(XGBoostTrainer pid=24886, ip=10.45.64.19)\u001b[0m Training in progress (30 seconds since last restart).\n",
      "\u001b[36m(_RemoteRayXGBoostActor pid=48660)\u001b[0m [16:47:28] task [xgboost.ray]:140110833609312 got new rank 2\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(XGBoostTrainer pid=24886, ip=10.45.64.19)\u001b[0m [RayXGBoost] Finished XGBoost training on training data with total N=13,833,129 in 46.33 seconds (38.52 pure XGBoost training time).\n",
      "\u001b[36m(XGBoostTrainer pid=24886, ip=10.45.64.19)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/a1jadhav/ray_results/XGBoostTrainer_2024-03-13_16-46-20/XGBoostTrainer_e4665_00001_1_eta=0.5000,max_depth=3,subsample=0.8000_2024-03-13_16-46-20/checkpoint_000000)\n",
      "\u001b[36m(XGBoostTrainer pid=49028)\u001b[0m [RayXGBoost] Created 3 new actors (3 total actors). Waiting until actors are ready for training.\n",
      "\u001b[36m(XGBoostTrainer pid=49028)\u001b[0m [RayXGBoost] Starting XGBoost training.\n",
      "\u001b[36m(_RemoteRayXGBoostActor pid=25448, ip=10.35.0.20)\u001b[0m [16:48:17] task [xgboost.ray]:139846690977296 got new rank 0\n",
      "\u001b[36m(XGBoostTrainer pid=49028)\u001b[0m Training in progress (31 seconds since last restart).\n",
      "\u001b[36m(_RemoteRayXGBoostActor pid=49302)\u001b[0m [16:48:18] task [xgboost.ray]:139962118601216 got new rank 2\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(XGBoostTrainer pid=49028)\u001b[0m [RayXGBoost] Finished XGBoost training on training data with total N=13,833,129 in 46.38 seconds (38.95 pure XGBoost training time).\n",
      "\u001b[36m(XGBoostTrainer pid=49028)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/a1jadhav/ray_results/XGBoostTrainer_2024-03-13_16-46-20/XGBoostTrainer_e4665_00002_2_eta=0.3000,max_depth=4,subsample=0.8000_2024-03-13_16-46-20/checkpoint_000000)\n",
      "\u001b[36m(XGBoostTrainer pid=25917, ip=10.45.64.19)\u001b[0m [RayXGBoost] Created 3 new actors (3 total actors). Waiting until actors are ready for training.\n",
      "\u001b[36m(XGBoostTrainer pid=25917, ip=10.45.64.19)\u001b[0m [RayXGBoost] Starting XGBoost training.\n",
      "\u001b[36m(_RemoteRayXGBoostActor pid=25702, ip=10.35.0.20)\u001b[0m [16:49:08] task [xgboost.ray]:140597969860064 got new rank 0\n",
      "\u001b[36m(XGBoostTrainer pid=25917, ip=10.45.64.19)\u001b[0m Training in progress (31 seconds since last restart).\n",
      "\u001b[36m(_RemoteRayXGBoostActor pid=49955)\u001b[0m [16:49:08] task [xgboost.ray]:140284243442224 got new rank 2\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(XGBoostTrainer pid=25917, ip=10.45.64.19)\u001b[0m [RayXGBoost] Finished XGBoost training on training data with total N=13,833,129 in 46.10 seconds (39.11 pure XGBoost training time).\n",
      "\u001b[36m(XGBoostTrainer pid=25917, ip=10.45.64.19)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/a1jadhav/ray_results/XGBoostTrainer_2024-03-13_16-46-20/XGBoostTrainer_e4665_00003_3_eta=0.5000,max_depth=4,subsample=0.8000_2024-03-13_16-46-20/checkpoint_000000)\n",
      "\u001b[36m(XGBoostTrainer pid=26109, ip=10.35.0.20)\u001b[0m [RayXGBoost] Created 3 new actors (3 total actors). Waiting until actors are ready for training.\n",
      "\u001b[36m(XGBoostTrainer pid=26109, ip=10.35.0.20)\u001b[0m [RayXGBoost] Starting XGBoost training.\n",
      "\u001b[36m(_RemoteRayXGBoostActor pid=26285, ip=10.35.0.20)\u001b[0m [16:50:00] task [xgboost.ray]:140343899240048 got new rank 0\n",
      "\u001b[36m(XGBoostTrainer pid=26109, ip=10.35.0.20)\u001b[0m Training in progress (30 seconds since last restart).\n",
      "\u001b[36m(_RemoteRayXGBoostActor pid=50315)\u001b[0m [16:50:01] task [xgboost.ray]:140636962646720 got new rank 2\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(XGBoostTrainer pid=26109, ip=10.35.0.20)\u001b[0m [RayXGBoost] Finished XGBoost training on training data with total N=13,833,129 in 52.31 seconds (43.38 pure XGBoost training time).\n",
      "\u001b[36m(XGBoostTrainer pid=26109, ip=10.35.0.20)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/a1jadhav/ray_results/XGBoostTrainer_2024-03-13_16-46-20/XGBoostTrainer_e4665_00004_4_eta=0.3000,max_depth=5,subsample=0.8000_2024-03-13_16-46-20/checkpoint_000000)\n",
      "\u001b[36m(XGBoostTrainer pid=26723, ip=10.35.0.20)\u001b[0m [RayXGBoost] Created 3 new actors (3 total actors). Waiting until actors are ready for training.\n",
      "\u001b[36m(XGBoostTrainer pid=26723, ip=10.35.0.20)\u001b[0m [RayXGBoost] Starting XGBoost training.\n",
      "\u001b[36m(_RemoteRayXGBoostActor pid=26877, ip=10.35.0.20)\u001b[0m [16:50:56] task [xgboost.ray]:140401745249808 got new rank 0\n",
      "\u001b[36m(XGBoostTrainer pid=26723, ip=10.35.0.20)\u001b[0m Training in progress (30 seconds since last restart).\n",
      "\u001b[36m(_RemoteRayXGBoostActor pid=50686)\u001b[0m [16:50:57] task [xgboost.ray]:140566900468464 got new rank 2\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(XGBoostTrainer pid=26723, ip=10.35.0.20)\u001b[0m [RayXGBoost] Finished XGBoost training on training data with total N=13,833,129 in 51.25 seconds (44.02 pure XGBoost training time).\n",
      "\u001b[36m(XGBoostTrainer pid=26723, ip=10.35.0.20)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/a1jadhav/ray_results/XGBoostTrainer_2024-03-13_16-46-20/XGBoostTrainer_e4665_00005_5_eta=0.5000,max_depth=5,subsample=0.8000_2024-03-13_16-46-20/checkpoint_000000)\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m [2024-03-13 16:51:39,491 E 26875 26875] logging.cc:97: Unhandled exception: St12system_error. what(): Invalid argument\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m [2024-03-13 16:51:39,626 E 26875 26875] logging.cc:104: Stack trace: \n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m  /home/ray/anaconda3/lib/python3.8/site-packages/ray/_raylet.so(+0x100531a) [0x7fd02b68131a] ray::operator<<()\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/ray/_raylet.so(+0x1007a58) [0x7fd02b683a58] ray::TerminateHandler()\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m /home/ray/anaconda3/bin/../lib/libstdc++.so.6(+0xb135a) [0x7fd02a50535a] __cxxabiv1::__terminate()\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m /home/ray/anaconda3/bin/../lib/libstdc++.so.6(+0xb13c5) [0x7fd02a5053c5]\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m /home/ray/anaconda3/bin/../lib/libstdc++.so.6(+0xb1658) [0x7fd02a505658]\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m /home/ray/anaconda3/bin/../lib/libstdc++.so.6(_ZSt20__throw_system_errori+0x85) [0x7fd02a4fc5e8] std::__throw_system_error()\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m /home/ray/anaconda3/bin/../lib/libstdc++.so.6(+0xdbe7e) [0x7fd02a52fe7e]\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/ray/_raylet.so(+0x7e7e49) [0x7fd02ae63e49] ray::core::ConcurrencyGroupManager<>::Stop()\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/ray/_raylet.so(_ZN3ray4core28CoreWorkerDirectTaskReceiver4StopEv+0x7b) [0x7fd02ae4a0bb] ray::core::CoreWorkerDirectTaskReceiver::Stop()\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/ray/_raylet.so(_ZN3ray4core10CoreWorker8ShutdownEv+0x230) [0x7fd02ae1d2e0] ray::core::CoreWorker::Shutdown()\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/ray/_raylet.so(+0xa41e4e) [0x7fd02b0bde4e] EventTracker::RecordExecution()\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/ray/_raylet.so(+0xa3b23e) [0x7fd02b0b723e] std::_Function_handler<>::_M_invoke()\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/ray/_raylet.so(+0xa3b6b6) [0x7fd02b0b76b6] boost::asio::detail::completion_handler<>::do_complete()\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/ray/_raylet.so(+0x10eeccb) [0x7fd02b76accb] boost::asio::detail::scheduler::do_run_one()\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/ray/_raylet.so(+0x10f0649) [0x7fd02b76c649] boost::asio::detail::scheduler::run()\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/ray/_raylet.so(+0x10f0d52) [0x7fd02b76cd52] boost::asio::io_context::run()\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/ray/_raylet.so(_ZN3ray4core10CoreWorker20RunTaskExecutionLoopEv+0xcd) [0x7fd02adef70d] ray::core::CoreWorker::RunTaskExecutionLoop()\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/ray/_raylet.so(_ZN3ray4core21CoreWorkerProcessImpl26RunWorkerTaskExecutionLoopEv+0x8c) [0x7fd02ae3174c] ray::core::CoreWorkerProcessImpl::RunWorkerTaskExecutionLoop()\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/ray/_raylet.so(_ZN3ray4core17CoreWorkerProcess20RunTaskExecutionLoopEv+0x1d) [0x7fd02ae318fd] ray::core::CoreWorkerProcess::RunTaskExecutionLoop()\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/ray/_raylet.so(+0x5b2757) [0x7fd02ac2e757] __pyx_pw_3ray_7_raylet_10CoreWorker_7run_task_loop()\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m ray::_QueueActor() [0x4ecb84] method_vectorcall_NOARGS\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m ray::_QueueActor(_PyEval_EvalFrameDefault+0x6b2) [0x4d87c2] _PyEval_EvalFrameDefault\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m ray::_QueueActor(_PyFunction_Vectorcall+0x106) [0x4e81a6] _PyFunction_Vectorcall\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m ray::_QueueActor(_PyEval_EvalFrameDefault+0x6b2) [0x4d87c2] _PyEval_EvalFrameDefault\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m ray::_QueueActor(_PyEval_EvalCodeWithName+0x2f1) [0x4d70d1] _PyEval_EvalCodeWithName\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m ray::_QueueActor(PyEval_EvalCodeEx+0x39) [0x585e29] PyEval_EvalCodeEx\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m ray::_QueueActor(PyEval_EvalCode+0x1b) [0x585deb] PyEval_EvalCode\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m ray::_QueueActor() [0x5a5bd1] run_eval_code_obj\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m ray::_QueueActor() [0x5a4bdf] run_mod\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m ray::_QueueActor() [0x45c538] pyrun_file\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m ray::_QueueActor(PyRun_SimpleFileExFlags+0x340) [0x45c0d9] PyRun_SimpleFileExFlags\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m ray::_QueueActor() [0x44fe8f] Py_RunMain.cold\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m ray::_QueueActor(Py_BytesMain+0x39) [0x579e89] Py_BytesMain\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf3) [0x7fd02c2fd083] __libc_start_main\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m ray::_QueueActor() [0x579d3d]\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m \n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m *** SIGABRT received at time=1710373899 on cpu 19 ***\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m PC: @     0x7fd02c31c00b  (unknown)  raise\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m     @     0x7fd02c639420  323374384  (unknown)\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m     @     0x7fd02a50535a  (unknown)  __cxxabiv1::__terminate()\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m     @     0x7fd02a505580  (unknown)  (unknown)\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m [2024-03-13 16:51:39,628 E 26875 26875] logging.cc:361: *** SIGABRT received at time=1710373899 on cpu 19 ***\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m [2024-03-13 16:51:39,628 E 26875 26875] logging.cc:361: PC: @     0x7fd02c31c00b  (unknown)  raise\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m [2024-03-13 16:51:39,628 E 26875 26875] logging.cc:361:     @     0x7fd02c639420  323374384  (unknown)\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m [2024-03-13 16:51:39,628 E 26875 26875] logging.cc:361:     @     0x7fd02a50535a  (unknown)  __cxxabiv1::__terminate()\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m [2024-03-13 16:51:39,629 E 26875 26875] logging.cc:361:     @     0x7fd02a505580  (unknown)  (unknown)\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m Fatal Python error: Aborted\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m \n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m Stack (most recent call first):\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/_private/worker.py\", line 847 in main_loop\n",
      "\u001b[36m(_QueueActor pid=26875, ip=10.35.0.20)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/_private/workers/default_worker.py\", line 282 in <module>\n",
      "\u001b[36m(XGBoostTrainer pid=27343, ip=10.35.0.20)\u001b[0m [RayXGBoost] Created 3 new actors (3 total actors). Waiting until actors are ready for training.\n",
      "\u001b[36m(XGBoostTrainer pid=27343, ip=10.35.0.20)\u001b[0m [RayXGBoost] Starting XGBoost training.\n",
      "\u001b[36m(_RemoteRayXGBoostActor pid=27497, ip=10.35.0.20)\u001b[0m [16:51:53] task [xgboost.ray]:140396583630304 got new rank 0\n",
      "\u001b[36m(XGBoostTrainer pid=27343, ip=10.35.0.20)\u001b[0m Training in progress (30 seconds since last restart).\n",
      "\u001b[36m(_RemoteRayXGBoostActor pid=51055)\u001b[0m [16:51:53] task [xgboost.ray]:140051437284032 got new rank 2\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(XGBoostTrainer pid=27343, ip=10.35.0.20)\u001b[0m [RayXGBoost] Finished XGBoost training on training data with total N=13,833,129 in 47.83 seconds (39.97 pure XGBoost training time).\n",
      "\u001b[36m(XGBoostTrainer pid=27343, ip=10.35.0.20)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/a1jadhav/ray_results/XGBoostTrainer_2024-03-13_16-46-20/XGBoostTrainer_e4665_00006_6_eta=0.3000,max_depth=3,subsample=1.0000_2024-03-13_16-46-20/checkpoint_000000)\n",
      "\u001b[36m(XGBoostTrainer pid=51424)\u001b[0m [RayXGBoost] Created 3 new actors (3 total actors). Waiting until actors are ready for training.\n",
      "\u001b[36m(XGBoostTrainer pid=51424)\u001b[0m [RayXGBoost] Starting XGBoost training.\n",
      "\u001b[36m(_RemoteRayXGBoostActor pid=27965, ip=10.35.0.20)\u001b[0m [16:52:43] task [xgboost.ray]:139742467241536 got new rank 0\n",
      "\u001b[36m(XGBoostTrainer pid=51424)\u001b[0m Training in progress (31 seconds since last restart).\n",
      "\u001b[36m(_RemoteRayXGBoostActor pid=51673)\u001b[0m [16:52:43] task [xgboost.ray]:139712004844176 got new rank 2\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(XGBoostTrainer pid=51424)\u001b[0m [RayXGBoost] Finished XGBoost training on training data with total N=13,833,129 in 41.69 seconds (34.20 pure XGBoost training time).\n",
      "\u001b[36m(XGBoostTrainer pid=51424)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/a1jadhav/ray_results/XGBoostTrainer_2024-03-13_16-46-20/XGBoostTrainer_e4665_00007_7_eta=0.5000,max_depth=3,subsample=1.0000_2024-03-13_16-46-20/checkpoint_000000)\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m [2024-03-13 16:53:16,145 E 27743 27743] logging.cc:97: Unhandled exception: St12system_error. what(): Invalid argument\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m [2024-03-13 16:53:16,280 E 27743 27743] logging.cc:104: Stack trace: \n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m  /home/ray/anaconda3/lib/python3.8/site-packages/ray/_raylet.so(+0x100531a) [0x7f6dd01a131a] ray::operator<<()\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/ray/_raylet.so(+0x1007a58) [0x7f6dd01a3a58] ray::TerminateHandler()\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m /home/ray/anaconda3/bin/../lib/libstdc++.so.6(+0xb135a) [0x7f6dcf02535a] __cxxabiv1::__terminate()\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m /home/ray/anaconda3/bin/../lib/libstdc++.so.6(+0xb13c5) [0x7f6dcf0253c5]\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m /home/ray/anaconda3/bin/../lib/libstdc++.so.6(+0xb1658) [0x7f6dcf025658]\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m /home/ray/anaconda3/bin/../lib/libstdc++.so.6(_ZSt20__throw_system_errori+0x85) [0x7f6dcf01c5e8] std::__throw_system_error()\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m /home/ray/anaconda3/bin/../lib/libstdc++.so.6(+0xdbe7e) [0x7f6dcf04fe7e]\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/ray/_raylet.so(+0x7e7e49) [0x7f6dcf983e49] ray::core::ConcurrencyGroupManager<>::Stop()\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/ray/_raylet.so(_ZN3ray4core28CoreWorkerDirectTaskReceiver4StopEv+0x7b) [0x7f6dcf96a0bb] ray::core::CoreWorkerDirectTaskReceiver::Stop()\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/ray/_raylet.so(_ZN3ray4core10CoreWorker8ShutdownEv+0x230) [0x7f6dcf93d2e0] ray::core::CoreWorker::Shutdown()\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/ray/_raylet.so(+0xa41e4e) [0x7f6dcfbdde4e] EventTracker::RecordExecution()\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/ray/_raylet.so(+0xa3b23e) [0x7f6dcfbd723e] std::_Function_handler<>::_M_invoke()\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/ray/_raylet.so(+0xa3b6b6) [0x7f6dcfbd76b6] boost::asio::detail::completion_handler<>::do_complete()\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/ray/_raylet.so(+0x10eeccb) [0x7f6dd028accb] boost::asio::detail::scheduler::do_run_one()\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/ray/_raylet.so(+0x10f0649) [0x7f6dd028c649] boost::asio::detail::scheduler::run()\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/ray/_raylet.so(+0x10f0d52) [0x7f6dd028cd52] boost::asio::io_context::run()\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/ray/_raylet.so(_ZN3ray4core10CoreWorker20RunTaskExecutionLoopEv+0xcd) [0x7f6dcf90f70d] ray::core::CoreWorker::RunTaskExecutionLoop()\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/ray/_raylet.so(_ZN3ray4core21CoreWorkerProcessImpl26RunWorkerTaskExecutionLoopEv+0x8c) [0x7f6dcf95174c] ray::core::CoreWorkerProcessImpl::RunWorkerTaskExecutionLoop()\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/ray/_raylet.so(_ZN3ray4core17CoreWorkerProcess20RunTaskExecutionLoopEv+0x1d) [0x7f6dcf9518fd] ray::core::CoreWorkerProcess::RunTaskExecutionLoop()\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/ray/_raylet.so(+0x5b2757) [0x7f6dcf74e757] __pyx_pw_3ray_7_raylet_10CoreWorker_7run_task_loop()\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m ray::_QueueActor() [0x4ecb84] method_vectorcall_NOARGS\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m ray::_QueueActor(_PyEval_EvalFrameDefault+0x6b2) [0x4d87c2] _PyEval_EvalFrameDefault\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m ray::_QueueActor(_PyFunction_Vectorcall+0x106) [0x4e81a6] _PyFunction_Vectorcall\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m ray::_QueueActor(_PyEval_EvalFrameDefault+0x6b2) [0x4d87c2] _PyEval_EvalFrameDefault\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m ray::_QueueActor(_PyEval_EvalCodeWithName+0x2f1) [0x4d70d1] _PyEval_EvalCodeWithName\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m ray::_QueueActor(PyEval_EvalCodeEx+0x39) [0x585e29] PyEval_EvalCodeEx\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m ray::_QueueActor(PyEval_EvalCode+0x1b) [0x585deb] PyEval_EvalCode\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m ray::_QueueActor() [0x5a5bd1] run_eval_code_obj\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m ray::_QueueActor() [0x5a4bdf] run_mod\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m ray::_QueueActor() [0x45c538] pyrun_file\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m ray::_QueueActor(PyRun_SimpleFileExFlags+0x340) [0x45c0d9] PyRun_SimpleFileExFlags\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m ray::_QueueActor() [0x44fe8f] Py_RunMain.cold\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m ray::_QueueActor(Py_BytesMain+0x39) [0x579e89] Py_BytesMain\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf3) [0x7f6dd0e1d083] __libc_start_main\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m ray::_QueueActor() [0x579d3d]\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m \n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m *** SIGABRT received at time=1710373996 on cpu 42 ***\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m PC: @     0x7f6dd0e3c00b  (unknown)  raise\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m     @     0x7f6dd1159420  (unknown)  (unknown)\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m     @     0x7f6dcf02535a  (unknown)  __cxxabiv1::__terminate()\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m     @     0x7f6dcf025580  (unknown)  (unknown)\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m [2024-03-13 16:53:16,282 E 27743 27743] logging.cc:361: *** SIGABRT received at time=1710373996 on cpu 42 ***\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m [2024-03-13 16:53:16,282 E 27743 27743] logging.cc:361: PC: @     0x7f6dd0e3c00b  (unknown)  raise\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m [2024-03-13 16:53:16,282 E 27743 27743] logging.cc:361:     @     0x7f6dd1159420  (unknown)  (unknown)\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m [2024-03-13 16:53:16,282 E 27743 27743] logging.cc:361:     @     0x7f6dcf02535a  (unknown)  __cxxabiv1::__terminate()\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m [2024-03-13 16:53:16,283 E 27743 27743] logging.cc:361:     @     0x7f6dcf025580  (unknown)  (unknown)\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m Fatal Python error: Aborted\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m \n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m Stack (most recent call first):\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/_private/worker.py\", line 847 in main_loop\n",
      "\u001b[36m(_QueueActor pid=27743, ip=10.45.64.19)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/_private/workers/default_worker.py\", line 282 in <module>\n",
      "\u001b[36m(XGBoostTrainer pid=28365, ip=10.35.0.20)\u001b[0m [RayXGBoost] Created 3 new actors (3 total actors). Waiting until actors are ready for training.\n",
      "\u001b[36m(XGBoostTrainer pid=28365, ip=10.35.0.20)\u001b[0m [RayXGBoost] Starting XGBoost training.\n",
      "\u001b[36m(_RemoteRayXGBoostActor pid=28520, ip=10.35.0.20)\u001b[0m [16:53:29] task [xgboost.ray]:140442619524624 got new rank 0\n",
      "\u001b[36m(XGBoostTrainer pid=28365, ip=10.35.0.20)\u001b[0m Training in progress (31 seconds since last restart).\n",
      "\u001b[36m(_RemoteRayXGBoostActor pid=52094)\u001b[0m [16:53:29] task [xgboost.ray]:139781187656432 got new rank 2\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(XGBoostTrainer pid=28365, ip=10.35.0.20)\u001b[0m [RayXGBoost] Finished XGBoost training on training data with total N=13,833,129 in 46.24 seconds (39.49 pure XGBoost training time).\n",
      "\u001b[36m(XGBoostTrainer pid=28365, ip=10.35.0.20)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/a1jadhav/ray_results/XGBoostTrainer_2024-03-13_16-46-20/XGBoostTrainer_e4665_00008_8_eta=0.3000,max_depth=4,subsample=1.0000_2024-03-13_16-46-20/checkpoint_000000)\n",
      "\u001b[36m(XGBoostTrainer pid=28404, ip=10.45.64.19)\u001b[0m [RayXGBoost] Created 3 new actors (3 total actors). Waiting until actors are ready for training.\n",
      "\u001b[36m(XGBoostTrainer pid=28404, ip=10.45.64.19)\u001b[0m [RayXGBoost] Starting XGBoost training.\n",
      "\u001b[36m(_RemoteRayXGBoostActor pid=28979, ip=10.35.0.20)\u001b[0m [16:54:23] task [xgboost.ray]:139634491708704 got new rank 0\n",
      "\u001b[36m(XGBoostTrainer pid=28404, ip=10.45.64.19)\u001b[0m Training in progress (31 seconds since last restart).\n",
      "\u001b[36m(_RemoteRayXGBoostActor pid=52718)\u001b[0m [16:54:23] task [xgboost.ray]:139985202150272 got new rank 2\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(XGBoostTrainer pid=28404, ip=10.45.64.19)\u001b[0m [RayXGBoost] Finished XGBoost training on training data with total N=13,833,129 in 48.33 seconds (39.02 pure XGBoost training time).\n",
      "\u001b[36m(XGBoostTrainer pid=28404, ip=10.45.64.19)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/a1jadhav/ray_results/XGBoostTrainer_2024-03-13_16-46-20/XGBoostTrainer_e4665_00009_9_eta=0.5000,max_depth=4,subsample=1.0000_2024-03-13_16-46-20/checkpoint_000000)\n",
      "\u001b[36m(XGBoostTrainer pid=29231, ip=10.35.0.20)\u001b[0m [RayXGBoost] Created 3 new actors (3 total actors). Waiting until actors are ready for training.\n",
      "\u001b[36m(XGBoostTrainer pid=29231, ip=10.35.0.20)\u001b[0m [RayXGBoost] Starting XGBoost training.\n",
      "\u001b[36m(_RemoteRayXGBoostActor pid=29386, ip=10.35.0.20)\u001b[0m [16:55:15] task [xgboost.ray]:140502811723232 got new rank 0\n",
      "\u001b[36m(XGBoostTrainer pid=29231, ip=10.35.0.20)\u001b[0m Training in progress (30 seconds since last restart).\n",
      "\u001b[36m(_RemoteRayXGBoostActor pid=53584)\u001b[0m [16:55:15] task [xgboost.ray]:139649056471648 got new rank 2\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(XGBoostTrainer pid=29231, ip=10.35.0.20)\u001b[0m [RayXGBoost] Finished XGBoost training on training data with total N=13,833,129 in 50.02 seconds (42.30 pure XGBoost training time).\n",
      "\u001b[36m(XGBoostTrainer pid=29231, ip=10.35.0.20)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/a1jadhav/ray_results/XGBoostTrainer_2024-03-13_16-46-20/XGBoostTrainer_e4665_00010_10_eta=0.3000,max_depth=5,subsample=1.0000_2024-03-13_16-46-20/checkpoint_000000)\n",
      "\u001b[36m(XGBoostTrainer pid=30003, ip=10.35.0.20)\u001b[0m [RayXGBoost] Created 3 new actors (3 total actors). Waiting until actors are ready for training.\n",
      "\u001b[36m(XGBoostTrainer pid=30003, ip=10.35.0.20)\u001b[0m [RayXGBoost] Starting XGBoost training.\n",
      "\u001b[36m(_RemoteRayXGBoostActor pid=30158, ip=10.35.0.20)\u001b[0m [16:56:09] task [xgboost.ray]:140212837201568 got new rank 0\n",
      "\u001b[36m(XGBoostTrainer pid=30003, ip=10.35.0.20)\u001b[0m Training in progress (31 seconds since last restart).\n",
      "\u001b[36m(_RemoteRayXGBoostActor pid=53955)\u001b[0m [16:56:09] task [xgboost.ray]:140375374920000 got new rank 2\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(XGBoostTrainer pid=30003, ip=10.35.0.20)\u001b[0m [RayXGBoost] Finished XGBoost training on training data with total N=13,833,129 in 51.77 seconds (43.19 pure XGBoost training time).\n",
      "2024-03-13 16:56:51,514\tINFO tune.py:1042 -- Total run time: 631.18 seconds (631.15 seconds for the tuning loop).\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m [2024-03-13 16:56:51,532 E 53952 53952] logging.cc:97: Unhandled exception: St12system_error. what(): Invalid argument\n"
     ]
    }
   ],
   "source": [
    "from ray import tune\n",
    "from ray.tune import Tuner\n",
    "from ray.train.xgboost import XGBoostTrainer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# store your answers in these\n",
    "best_result = None\n",
    "result_grid = None\n",
    "\n",
    "train, val, = train_data.train_test_split(test_size=0.25, shuffle=True)\n",
    "\n",
    "trainer = XGBoostTrainer(\n",
    "    label_column=\"overall\",\n",
    "    params={\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"max_depth\": 4,\n",
    "        \"subsample\": 0.8,\n",
    "        \"eta\": 0.3\n",
    "    },\n",
    "    scaling_config=ScalingConfig(num_workers=3, resources_per_worker = {\"CPU\":6}, use_gpu = False),\n",
    "    datasets={\"train\": train, \"val\":val}\n",
    ")\n",
    "\n",
    "# Create Tuner\n",
    "tuner = Tuner(\n",
    "    trainer,\n",
    "    # Add some parameters to tune\n",
    "    param_space={\"params\": {\n",
    "        \"max_depth\": tune.grid_search([3,4,5]),\n",
    "        \"subsample\": tune.grid_search([0.8, 1.0]),\n",
    "        \"eta\": tune.grid_search([0.3, 0.5]),}\n",
    "                },\n",
    "    # Specify tuning behavior\n",
    "    tune_config=tune.TuneConfig(metric=\"train-rmse\", mode=\"min\", num_samples=1),\n",
    ")\n",
    "\n",
    "\n",
    "#Saving Results\n",
    "result_grid = tuner.fit()\n",
    "best_result = result_grid.get_best_result(metric=\"val-rmse\", mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result(\n",
      "  metrics={'train-rmse': 0.8671578920302253, 'val-rmse': 0.867836184329676},\n",
      "  path='/home/a1jadhav/ray_results/XGBoostTrainer_2024-03-13_16-46-20/XGBoostTrainer_e4665_00005_5_eta=0.5000,max_depth=5,subsample=0.8000_2024-03-13_16-46-20',\n",
      "  filesystem='local',\n",
      "  checkpoint=Checkpoint(filesystem=local, path=/home/a1jadhav/ray_results/XGBoostTrainer_2024-03-13_16-46-20/XGBoostTrainer_e4665_00005_5_eta=0.5000,max_depth=5,subsample=0.8000_2024-03-13_16-46-20/checkpoint_000000)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=30003, ip=10.35.0.20)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/a1jadhav/ray_results/XGBoostTrainer_2024-03-13_16-46-20/XGBoostTrainer_e4665_00011_11_eta=0.5000,max_depth=5,subsample=1.0000_2024-03-13_16-46-20/checkpoint_000000)\n"
     ]
    }
   ],
   "source": [
    "print(best_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e14668fb01fc00965e3858708be634e0",
     "grade": false,
     "grade_id": "cell-50f29ff46bfb2d7f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now, \n",
    "1. Get the root mean squared error for the test dataset using the best result from the hyperparameter tuning experiments.\n",
    "2. Report the validation rmse values for the best model as well as the given configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0abba6771029c66fac88eb3948b7d18d",
     "grade": false,
     "grade_id": "cell-f729ed2a7b3039c6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_task_2_2_results(result_grid: tune.ResultGrid, best_result: ray.train.Result):\n",
    "    res = {\n",
    "       \"test_rmse\": None, # test rmse for the best model\n",
    "        \"valid_rmse\": None, # validation rmse for the best model\n",
    "        \"valid_depth_5_eta_0.3_subsample_0.8\": None, # validation rmse for max_depth=5, eta=0.3, subsample=0.8\n",
    "        \"valid_depth_4_eta_0.3_subsample_1\": None, # validation rmse for max_depth=4, eta=0.3, subsample=1\n",
    "        \"valid_depth_3_eta_0.5_subsample_1\": None, # validation rmse for max_depth=3, eta=0.5, subsample=1\n",
    "    }\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    #test-rmse for best model\n",
    "    test_rmse_se = predict_xgboost(test_dataset, best_result)\n",
    "    res[\"test_rmse\"] = math.sqrt(test_rmse_se.sum()/test_rmse_se.count())\n",
    "    \n",
    "    #best model val rmse\n",
    "    res[\"valid_rmse\"] = best_result.metrics['val-rmse']\n",
    "    \n",
    "    for trial in result_grid:\n",
    "        trial_params = trial.config[\"params\"]\n",
    "        if trial_params[\"max_depth\"] == 5 and trial_params[\"eta\"] == 0.3 and trial_params[\"subsample\"] == 0.8:\n",
    "            res[\"valid_depth_5_eta_0.3_subsample_0.8\"] = trial.metrics.get(\"val-rmse\")\n",
    "        elif trial_params[\"max_depth\"] == 4 and trial_params[\"eta\"] == 0.3 and trial_params[\"subsample\"] == 1.0:\n",
    "            res[\"valid_depth_4_eta_0.3_subsample_1\"] = trial.metrics.get(\"val-rmse\")\n",
    "        elif trial_params[\"max_depth\"] == 3 and trial_params[\"eta\"] == 0.5 and trial_params[\"subsample\"] == 1.0:\n",
    "            res[\"valid_depth_3_eta_0.5_subsample_1\"] = trial.metrics.get(\"val-rmse\")\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d8c868f69f4922d5145e5ded168e5e12",
     "grade": false,
     "grade_id": "cell-caf5fe6461b02dd9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 16:56:51,599\tINFO set_read_parallelism.py:115 -- Using autodetected parallelism=200 for stage ReadParquet to satisfy DataContext.get_current().min_parallelism=200.\n",
      "2024-03-13 16:56:51,600\tINFO set_read_parallelism.py:122 -- To satisfy the requested parallelism of 200, each read task output is split into 9 smaller blocks.\n",
      "2024-03-13 16:56:51,601\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(Predictor)] -> LimitOperator[limit=1]\n",
      "2024-03-13 16:56:51,602\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-13 16:56:51,603\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m [2024-03-13 16:56:51,608 E 53952 53952] logging.cc:104: Stack trace: \n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m  /home/ray/anaconda3/lib/python3.8/site-packages/ray/_raylet.so(+0x100531a) [0x7fe4ec20431a] ray::operator<<()\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/ray/_raylet.so(+0x1007a58) [0x7fe4ec206a58] ray::TerminateHandler()\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m /home/ray/anaconda3/bin/../lib/libstdc++.so.6(+0xb135a) [0x7fe4eb08835a] __cxxabiv1::__terminate()\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m /home/ray/anaconda3/bin/../lib/libstdc++.so.6(+0xb13c5) [0x7fe4eb0883c5]\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m /home/ray/anaconda3/bin/../lib/libstdc++.so.6(+0xb1658) [0x7fe4eb088658]\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m /home/ray/anaconda3/bin/../lib/libstdc++.so.6(_ZSt20__throw_system_errori+0x85) [0x7fe4eb07f5e8] std::__throw_system_error()\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m /home/ray/anaconda3/bin/../lib/libstdc++.so.6(+0xdbe7e) [0x7fe4eb0b2e7e]\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/ray/_raylet.so(+0x7e7e49) [0x7fe4eb9e6e49] ray::core::ConcurrencyGroupManager<>::Stop()\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/ray/_raylet.so(_ZN3ray4core28CoreWorkerDirectTaskReceiver4StopEv+0x7b) [0x7fe4eb9cd0bb] ray::core::CoreWorkerDirectTaskReceiver::Stop()\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/ray/_raylet.so(_ZN3ray4core10CoreWorker8ShutdownEv+0x230) [0x7fe4eb9a02e0] ray::core::CoreWorker::Shutdown()\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/ray/_raylet.so(+0xa41e4e) [0x7fe4ebc40e4e] EventTracker::RecordExecution()\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/ray/_raylet.so(+0xa3b23e) [0x7fe4ebc3a23e] std::_Function_handler<>::_M_invoke()\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/ray/_raylet.so(+0xa3b6b6) [0x7fe4ebc3a6b6] boost::asio::detail::completion_handler<>::do_complete()\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/ray/_raylet.so(+0x10eeccb) [0x7fe4ec2edccb] boost::asio::detail::scheduler::do_run_one()\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/ray/_raylet.so(+0x10f0649) [0x7fe4ec2ef649] boost::asio::detail::scheduler::run()\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/ray/_raylet.so(+0x10f0d52) [0x7fe4ec2efd52] boost::asio::io_context::run()\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/ray/_raylet.so(_ZN3ray4core10CoreWorker20RunTaskExecutionLoopEv+0xcd) [0x7fe4eb97270d] ray::core::CoreWorker::RunTaskExecutionLoop()\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/ray/_raylet.so(_ZN3ray4core21CoreWorkerProcessImpl26RunWorkerTaskExecutionLoopEv+0x8c) [0x7fe4eb9b474c] ray::core::CoreWorkerProcessImpl::RunWorkerTaskExecutionLoop()\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/ray/_raylet.so(_ZN3ray4core17CoreWorkerProcess20RunTaskExecutionLoopEv+0x1d) [0x7fe4eb9b48fd] ray::core::CoreWorkerProcess::RunTaskExecutionLoop()\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m /home/ray/anaconda3/lib/python3.8/site-packages/ray/_raylet.so(+0x5b2757) [0x7fe4eb7b1757] __pyx_pw_3ray_7_raylet_10CoreWorker_7run_task_loop()\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m ray::_QueueActor() [0x4ecb84] method_vectorcall_NOARGS\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m ray::_QueueActor(_PyEval_EvalFrameDefault+0x6b2) [0x4d87c2] _PyEval_EvalFrameDefault\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m ray::_QueueActor(_PyFunction_Vectorcall+0x106) [0x4e81a6] _PyFunction_Vectorcall\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m ray::_QueueActor(_PyEval_EvalFrameDefault+0x6b2) [0x4d87c2] _PyEval_EvalFrameDefault\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m ray::_QueueActor(_PyEval_EvalCodeWithName+0x2f1) [0x4d70d1] _PyEval_EvalCodeWithName\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m ray::_QueueActor(PyEval_EvalCodeEx+0x39) [0x585e29] PyEval_EvalCodeEx\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m ray::_QueueActor(PyEval_EvalCode+0x1b) [0x585deb] PyEval_EvalCode\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m ray::_QueueActor() [0x5a5bd1] run_eval_code_obj\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m ray::_QueueActor() [0x5a4bdf] run_mod\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m ray::_QueueActor() [0x45c538] pyrun_file\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m ray::_QueueActor(PyRun_SimpleFileExFlags+0x340) [0x45c0d9] PyRun_SimpleFileExFlags\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m ray::_QueueActor() [0x44fe8f] Py_RunMain.cold\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m ray::_QueueActor(Py_BytesMain+0x39) [0x579e89] Py_BytesMain\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf3) [0x7fe4ece80083] __libc_start_main\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m ray::_QueueActor() [0x579d3d]\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m \n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m *** SIGABRT received at time=1710374211 on cpu 120 ***\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m PC: @     0x7fe4ece9f00b  (unknown)  raise\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m     @     0x7fe4ed1bc420  1000396992  (unknown)\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m     @     0x7fe4eb08835a  (unknown)  __cxxabiv1::__terminate()\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m     @     0x7fe4eb088580  (unknown)  (unknown)\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m [2024-03-13 16:56:51,609 E 53952 53952] logging.cc:361: *** SIGABRT received at time=1710374211 on cpu 120 ***\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m [2024-03-13 16:56:51,609 E 53952 53952] logging.cc:361: PC: @     0x7fe4ece9f00b  (unknown)  raise\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m [2024-03-13 16:56:51,609 E 53952 53952] logging.cc:361:     @     0x7fe4ed1bc420  1000396992  (unknown)\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m [2024-03-13 16:56:51,609 E 53952 53952] logging.cc:361:     @     0x7fe4eb08835a  (unknown)  __cxxabiv1::__terminate()\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m [2024-03-13 16:56:51,609 E 53952 53952] logging.cc:361:     @     0x7fe4eb088580  (unknown)  (unknown)\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m Fatal Python error: Aborted\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m \n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m Stack (most recent call first):\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/_private/worker.py\", line 847 in main_loop\n",
      "\u001b[36m(_QueueActor pid=53952)\u001b[0m   File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/_private/workers/default_worker.py\", line 282 in <module>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 16:56:54,726\tINFO set_read_parallelism.py:115 -- Using autodetected parallelism=200 for stage ReadParquet to satisfy DataContext.get_current().min_parallelism=200.\n",
      "2024-03-13 16:56:54,728\tINFO set_read_parallelism.py:122 -- To satisfy the requested parallelism of 200, each read task output is split into 9 smaller blocks.\n",
      "2024-03-13 16:56:54,728\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(Predictor)] -> AllToAllOperator[Aggregate] -> LimitOperator[limit=1]\n",
      "2024-03-13 16:56:54,730\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-13 16:56:54,730\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- Aggregate 1:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Map 2:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Reduce 3:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 16:57:01,145\tINFO set_read_parallelism.py:115 -- Using autodetected parallelism=200 for stage ReadParquet to satisfy DataContext.get_current().min_parallelism=200.\n",
      "2024-03-13 16:57:01,147\tINFO set_read_parallelism.py:122 -- To satisfy the requested parallelism of 200, each read task output is split into 9 smaller blocks.\n",
      "2024-03-13 16:57:01,148\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(Predictor)]\n",
      "2024-03-13 16:57:01,149\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-13 16:57:01,150\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res_2_2 = get_task_2_2_results(result_grid, best_result)\n",
    "with open(\"res_2_2.json\", \"w\") as f:\n",
    "    json.dump(res_2_2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4839304491826befcc567edd4cdf027a",
     "grade": false,
     "grade_id": "cell-e49486e627c4fdec",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# shutdown!\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
